{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"data/pkl_fine\"\n",
    "in_file = \"jihualde_CV.pkl\"\n",
    "out_dir = \"data/json/\"\n",
    "out_file = \"data_fine.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = f'{in_dir}/{in_file}'\n",
    "out_path = f'{out_dir}/{out_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(in_path):\n",
    "    with open(in_path, \"rb\") as f_in, open(out_path, \"w\") as f_out:\n",
    "        data = pkl.load(f_in)\n",
    "        json_format = data.json_format\n",
    "        lines = data.wrapper.lines\n",
    "        for record in tqdm(data.record):\n",
    "            # print(record)\n",
    "            buf_idx = record['from']\n",
    "            stk_idx = record['to']\n",
    "            type_str = record['type']\n",
    "            buf_string = None\n",
    "            stk_string = None\n",
    "            lbuf = None\n",
    "            rbuf = None \n",
    "            lstk = None \n",
    "            rstk = None \n",
    "            hstk = None\n",
    "            boldbuf = None\n",
    "            italbuf = None\n",
    "            boldstk = None\n",
    "            italstk = None\n",
    "            hbuf = None\n",
    "            if(buf_idx == -1):\n",
    "                buf_string = \"$ROOT\"\n",
    "                lbuf = 0\n",
    "                rbuf = 100\n",
    "                hbuf = 30\n",
    "                boldbuf = 0\n",
    "                italbuf = 0\n",
    "            else:\n",
    "                buf_string = \"$ROOT\" if buf_idx == -1 else json_format[buf_idx]['text']\n",
    "                lbuf = json_format[buf_idx]['x']\n",
    "                rbuf = json_format[buf_idx]['x'] + json_format[buf_idx]['width']\n",
    "                hbuf = int(json_format[buf_idx]['height'])\n",
    "                linebuf = lines[json_format[buf_idx]['page']][json_format[buf_idx]['idx_in_page']]\n",
    "                fontname = linebuf.fontname.lower()\n",
    "                boldbuf = 1 if \"bold\" in fontname else 0\n",
    "                italbuf = 1 if \"italic\" in fontname else 0\n",
    "\n",
    "            if(stk_idx == -1):\n",
    "                stk_string = \"$ROOT\"\n",
    "                lstk = 0\n",
    "                rstk = 100\n",
    "                hstk = 30\n",
    "                boldbuf = 0\n",
    "                italbuf = 0\n",
    "            else:\n",
    "                stk_string = \"$ROOT\" if stk_idx == -1 else json_format[stk_idx]['text']\n",
    "                lstk = json_format[stk_idx]['x']\n",
    "                rstk = json_format[stk_idx]['x'] + json_format[stk_idx]['width']\n",
    "                hstk = int(json_format[stk_idx]['height'])\n",
    "                linebuf = lines[json_format[stk_idx]['page']][json_format[stk_idx]['idx_in_page']]\n",
    "                fontname = linebuf.fontname.lower()\n",
    "                boldbuf = 1 if \"bold\" in fontname else 0\n",
    "                italbuf = 1 if \"italic\" in fontname else 0\n",
    "            yield {\n",
    "                'buf_str': buf_string,\n",
    "                'lbuf': lbuf,\n",
    "                'rbuf': rbuf,\n",
    "                'hbuf': hbuf,\n",
    "                'boldbuf': boldbuf,\n",
    "                'italbuf': italbuf,\n",
    "                'stk_str': stk_string,\n",
    "                'lstk': lstk,\n",
    "                'rstk': rstk,\n",
    "                'boldstk': boldstk,\n",
    "                'italstk': italstk,\n",
    "                'type': type_str,\n",
    "                'hstk': hstk\n",
    "            }\n",
    "            # print(f'{buf_string},{stk_string},{type_str}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1777237566.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    entry['to'] =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# fix a bug where the discard function had the from and to indices both point to themselves \n",
    "\n",
    "def fix_discard(in_path):\n",
    "    \n",
    "    data = None\n",
    "    print(in_path)\n",
    "    with open(in_path, \"rb\") as f_in:\n",
    "        data = pkl.load(f_in)\n",
    "\n",
    "    stack = [-1] \n",
    "\n",
    "    for entry in data.record:\n",
    "        print(\"ORIGINAL\", entry)\n",
    "        if(entry['type'] == 'pop'):\n",
    "            stack.pop()\n",
    "        if(entry['type'] == 'merge'):\n",
    "            stack.pop()\n",
    "            stack.append(entry['from'])\n",
    "        if(entry['type'] == 'subordinate'):\n",
    "            stack.append(entry['from'])\n",
    "        if(entry['type'] == 'discard'):\n",
    "            entry['to'] = stack[-1]\n",
    "        entry['to'] = \n",
    "\n",
    "    with open(in_path, \"wb\") as f_out:\n",
    "        pkl.dump(data, f_out)\n",
    "        # above line is pretty dangerous, should wait until everything is ready\n",
    "\n",
    "\n",
    "def lengthen_sentences(in_path, out_path):\n",
    "    data = None\n",
    "    print(in_path)\n",
    "    with open(in_path, \"rb\") as f_in:\n",
    "        data = pkl.load(f_in)\n",
    "\n",
    "    stack = [-1] \n",
    "    current_text = \"\"\n",
    "    for entry in data.record:\n",
    "        print(\"ORIGINAL\", entry)\n",
    "        if(entry['type'] == 'pop'):\n",
    "            stack.pop()\n",
    "        if(entry['type'] == 'merge'):\n",
    "            stack.pop()\n",
    "            stack.append(entry['from'])\n",
    "        if(entry['type'] == 'subordinate'):\n",
    "            stack.append(entry['from'])\n",
    "        if(entry['type'] == 'discard'):\n",
    "            entry['to'] = stack[-1]\n",
    "        entry['to'] = \n",
    "\n",
    "    with open(out_path, \"wb\") as f_out:\n",
    "        pkl.dump(data, f_out)\n",
    "        # above line is pretty dangerous, should wait until everything is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_to_json(in_dir = \"data/pkl_fine\", out_dir = \"data/json/\", out_name = \"data_fine.json\"):\n",
    "    to_write = {\n",
    "        'buf_str': [],\n",
    "        'lbuf': [],\n",
    "        'rbuf': [],\n",
    "        'hbuf': [],\n",
    "        'boldbuf': [],\n",
    "        'italbuf': [],\n",
    "        'stk_str': [],\n",
    "        'lstk': [],\n",
    "        'rstk': [],\n",
    "        'hstk': [],\n",
    "        'boldstk': [],\n",
    "        'italstk': [],\n",
    "        'type': []\n",
    "    }\n",
    "\n",
    "    for file in os.listdir(in_dir):\n",
    "        full_path = f'{in_dir}/{file}'\n",
    "        print(full_path)\n",
    "        if(os.path.isfile(full_path)):\n",
    "            for entry in get_record(full_path):\n",
    "                for key, val in entry.items():\n",
    "                    to_write[key].append(val)\n",
    "                    # print(key, val)\n",
    "    # print(to_write)\n",
    "    print(f'Found {len(to_write[\"buf_str\"])} elements')\n",
    "    out_path = f'{out_dir}/{out_name}'  \n",
    "\n",
    "    with open(out_path, \"w\") as f_out:\n",
    "        json.dump(to_write, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/pkl_fine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pkl_to_json()\n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mpkl_to_json\u001b[0;34m(in_dir, out_dir, out_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpkl_to_json\u001b[39m(in_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/pkl_fine\u001b[39m\u001b[39m\"\u001b[39m, out_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/json/\u001b[39m\u001b[39m\"\u001b[39m, out_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata_fine.json\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     to_write \u001b[39m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbuf_str\u001b[39m\u001b[39m'\u001b[39m: [],\n\u001b[1;32m      4\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlbuf\u001b[39m\u001b[39m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: []\n\u001b[1;32m     16\u001b[0m     }\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(in_dir):\n\u001b[1;32m     19\u001b[0m         full_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00min_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     20\u001b[0m         \u001b[39mprint\u001b[39m(full_path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/pkl_fine'"
     ]
    }
   ],
   "source": [
    "pkl_to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff3b2c9d663614f3977b65735ceb4b5f1b8eea6ba2762bc66636352610c8026c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
